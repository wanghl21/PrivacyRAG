{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_large_jsonl(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            yield json.loads(line)\n",
    "\n",
    "# 读取jsonl文件的行数\n",
    "def count_jsonl(file_path):\n",
    "    count = 0\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            count += 1\n",
    "    return count\n",
    "# file_path = '/data01/huangyuanhong/corpora2/corpora/wiki/enwiki-dec2021/text-list-100-sec.jsonl'\n",
    "# file_path = './wiki/enwiki-dec2021/infobox.jsonl'\n",
    "# file_path = '/data/huangyuanhong/corpora/enwiki-dec2021/text-list-100-sec.jsonl'\n",
    "\n",
    "# # 读取大文件,每次读取并返回batch_size行\n",
    "# def read_large_jsonl_lines(file_path, batch_size=1000):\n",
    "#     with open(file_path, 'r') as f:\n",
    "#         while True:\n",
    "#             lines = f.readlines(batch_size)\n",
    "#             if not lines:\n",
    "#                 break\n",
    "#             for line in lines:\n",
    "#                 yield json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_n_lines(input_file, output_file, n=2000000):\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        for i, line in enumerate(infile):\n",
    "            if i < n:\n",
    "                outfile.write(line)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "# 使用示例\n",
    "input_file = '/data/huangyuanhong/corpora/enwiki-dec2021/text-list-100-sec.jsonl'  # 输入文件路径\n",
    "output_file = '/data/huangyuanhong/corpora/enwiki-dec2021/train/train-2000000.jsonl'  # 输出文件路径\n",
    "extract_first_n_lines(input_file, output_file, n=2000000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_last_n_lines(input_file, output_file, n=10000):\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "        # 读取所有行\n",
    "        lines = infile.readlines()\n",
    "    \n",
    "    # 取最后 n 行并反转顺序\n",
    "    last_n_lines = lines[-n:][::-1]\n",
    "    \n",
    "    # 写入输出文件\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        outfile.writelines(last_n_lines)\n",
    "\n",
    "\n",
    "\n",
    "input_file = '/data/huangyuanhong/corpora/enwiki-dec2021/text-list-100-sec.jsonl'  # 输入文件路径\n",
    "output_file = '/data/huangyuanhong/corpora/enwiki-dec2021/test/test-10000.jsonl'  # 输出文件路径\n",
    "extract_last_n_lines(input_file, output_file, n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0', 'title': 'Trichocladus crinitus', 'section': '', 'text': ' Trichocladus crinitus is a species of the genus Trichocladus, in the family Hamamelidaceae. It is also called black witch-hazel.'}\n"
     ]
    }
   ],
   "source": [
    "# file_path = '/data/huangyuanhong/corpora/enwiki-dec2021/infobox.jsonl'\n",
    "file_path = '/data/huangyuanhong/corpora/enwiki-dec2021/text-list-100-sec.jsonl'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        count=0\n",
    "        for line in file:\n",
    "            count += 1\n",
    "            text = json.loads(line)\n",
    "            print(text)\n",
    "            if(count==2000000):\n",
    "                break\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将大型jsonl文件分割成多个小文件\n",
    "def split_large_jsonl(file_path,output_path, batch_size=1000):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = []\n",
    "        count = 0\n",
    "        for line in file:\n",
    "            lines.append(line)\n",
    "            count += 1\n",
    "            if count % batch_size == 0:\n",
    "                with open(f'{output_path}/{count}.jsonl', 'w', encoding='utf-8') as f:\n",
    "                    f.writelines(lines)\n",
    "                lines = []\n",
    "        if lines:\n",
    "            with open(f'{output_path}/{count}.jsonl', 'w', encoding='utf-8') as f:\n",
    "                f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_large_jsonl(\"/data01/huangyuanhong/corpora/wiki/enwiki-dec2021/text-list-100-sec.jsonl\", \"/data01/huangyuanhong/corpora/wiki/enwiki-dec2021/split/\",10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_obj = read_large_jsonl(file_path)\n",
    "with open(\"/data01/huangyuanhong/corpora/wiki/enwiki-dec2021/test/test1-29609000.jsonl\", \"w\") as f:\n",
    "    index = 0\n",
    "    for i in range(29609000):\n",
    "        next(json_obj)\n",
    "    for line in json_obj:\n",
    "        index += 1\n",
    "        if index > 1000:\n",
    "            break\n",
    "        f.write(json.dumps(line) + '\\n')\n",
    "        # print(line)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_obj = read_large_jsonl(file_path)\n",
    "with open(\"/data01/huangyuanhong/corpora/wiki/enwiki-dec2021/test/test2-10523000.jsonl\", \"w\") as f:\n",
    "    index = 0\n",
    "    for i in range(10523000):\n",
    "        next(json_obj)\n",
    "    for line in json_obj:\n",
    "        index += 1\n",
    "        if index > 1000:\n",
    "            break\n",
    "        f.write(json.dumps(line) + '\\n')\n",
    "        # print(line)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_obj = read_large_jsonl(file_path)\n",
    "with open(\"/data01/huangyuanhong/corpora/wiki/enwiki-dec2021/test-2000.jsonl\", \"w\") as f:\n",
    "    index = 0\n",
    "    for line in json_obj:\n",
    "        index+=1\n",
    "        if index > 1000:\n",
    "            break\n",
    "    for line in json_obj:\n",
    "        index += 1\n",
    "        if index > 2000:\n",
    "            break\n",
    "        f.write(json.dumps(line) + '\\n')\n",
    "        # print(line)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save infobox+text to tsv\n",
    "# def save_infobox_text_tsv(text_path, infor_path, save_path):\n",
    "#     index = 0\n",
    "#     with open(save_path, \"w\", encoding=\"utf-8\") as save_file:\n",
    "#         for line in read_large_jsonl(text_path):\n",
    "#             save_file.write(f\"{line['id']}\\t{line['title']} | {line['text'].replace('\\n','\\\\n')}\\n\")\n",
    "#             index += 1\n",
    "#         for line in read_large_jsonl(infor_path):\n",
    "#             save_file.write(f\"{index}\\t{line['title']} | {line['text'].replace('\\n','\\\\n')}\\n\")\n",
    "#             index += 1\n",
    "\n",
    "# save_infobox_text_tsv('./wiki/enwiki-dec2021/text-list-100-sec.jsonl', './wiki/enwiki-dec2021/infobox.jsonl', './wiki/enwiki-dec2021/infobox-text.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37507469\n"
     ]
    }
   ],
   "source": [
    "count = count_jsonl('./wiki/enwiki-dec2021/infobox-text.tsv')\n",
    "print(count) # 共37507469"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who was the man behind The Chipmunks? 29609432\n",
    "What star sign is Jamie Lee Curtis? 10523191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Alvin and the Chipmunks, originally David Seville and the Chipmunks or simply The Chipmunks\"\n",
    "# print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '23438835', 'title': \"Kids' Choice Award for Favorite Cartoon\", 'section': '6 Times', 'text': 'ALVINNN!!! and the Chipmunks '}\n"
     ]
    }
   ],
   "source": [
    "json_obj = read_large_jsonl(file_path)\n",
    "# # 读取29635173行\n",
    "# for i in range(29609432):\n",
    "#     a = next(json_obj)\n",
    "\n",
    "# 读取10523191行\n",
    "for i in range(23438835+1):\n",
    "    a = next(json_obj)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16518/33176581 [00:00<03:20, 165145.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 29609432/33176581 [02:36<00:18, 189672.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Alvin and the Chipmunks, originally David Seville and the Chipmunks or simply The Chipmunks, are an American animated virtual band created by Ross Bagdasarian for a novelty record in 1958. The group consists of three singing animated anthropomorphic chipmunks named Alvin, Simon, and Theodore. They are managed by their human adoptive father, David \"Dave\" Seville. Bagdasarian provided the group's voices sped up to create high-pitched squeaky voices (which wasn't entirely new to him, having worked on \"Witch Doctor\" earned the record two Grammy Awards for engineering). \"The Chipmunk Song\" became a number-one single in the United States. After Bagdasarian died in 1972, the characters’ voices were provided by his son Ross Bagdasarian Jr. and the latter's wife Janice Karman in the subsequent incarnations of \n",
      "29609432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "file_path = \"/data01/huangyuanhong/corpora/wiki/enwiki-dec2021/text-list-100-sec.jsonl\"\n",
    "\n",
    "# 使用示例\n",
    "# for json_obj in read_large_jsonl(file_path):\n",
    "#     if json_obj['text'] == target:\n",
    "#         print(index)\n",
    "#         break\n",
    "# size = count_jsonl(file_path)\n",
    "# print(size)\n",
    "index = 0\n",
    "pbar = tqdm(range(33176581))\n",
    "json_obj = read_large_jsonl(file_path)\n",
    "for i in pbar:\n",
    "    a = next(json_obj)\n",
    "    if target in a['text']:\n",
    "        print(a['text'])\n",
    "        print(i)\n",
    "        break\n",
    "    \n",
    "\n",
    "# for json_obj in pb.iter(read_large_jsonl(file_path), total=1000):\n",
    "#     if json_obj['text'] == target:\n",
    "#         print(index)\n",
    "#         break\n",
    "#     index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '10523191', 'title': 'Jamie Lee Curtis', 'section': '', 'text': \" Jamie Lee Curtis (born November 22, 1958) is an American actress and writer. She is the recipient of several accolades, including a British Academy Film Award, two Golden Globe Awards and a star on the Hollywood Walk of Fame in 1998. Curtis made her film acting debut as Laurie Strode in John Carpenter's horror film Halloween (1978), which established her as a scream queen, and she thereafter appeared in a string of horror films, including The Fog, Prom Night, Terror Train (all 1980) and Roadgames (1981). She reprised the role of Laurie in the sequels Halloween II (1981), Halloween H20: 20 Years Later (1998), Halloween: Resurrection (2002), Halloween (2018), and Halloween Kills (2021). Her filmography is largely characterized by independent film that have been box-office successes, with 8 of her lead-actress credits \"}\n"
     ]
    }
   ],
   "source": [
    "json_obj = read_large_jsonl(file_path)\n",
    "# # 读取29635173行\n",
    "# for i in range(29609432):\n",
    "#     a = next(json_obj)\n",
    "\n",
    "# 读取10523191行\n",
    "for i in range(10523191):\n",
    "    a = next(json_obj)\n",
    "\n",
    "# 15146143\n",
    "a = next(json_obj)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ./wiki/enwiki-dec2021/collection1Madd2.tsv\n"
     ]
    }
   ],
   "source": [
    "# 将`text-list-100-sec.jsonl`以`pid \\t passage text`格式保存至`collection.tsv`\n",
    "file_path = './wiki/enwiki-dec2021/text-list-100-sec.jsonl'\n",
    "# output_path = './wiki/enwiki-dec2021/collection1000_2_zero.tsv'\n",
    "# output_path = './wiki/enwiki-dec2021/collection1M.tsv'\n",
    "output_path = './wiki/enwiki-dec2021/collection1Madd2.tsv'\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as output_file:\n",
    "    json_obj = read_large_jsonl(file_path)\n",
    "    # for i in range(29609000):\n",
    "    #     a = next(json_obj)\n",
    "    for i in range(1000):\n",
    "        a = next(json_obj)\n",
    "        output_file.write(f\"{i}\\t{a['text']}\\n\")\n",
    "print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取tsv文件\n",
    "def read_tsv(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            data.append(line.strip().split(\"\\t\")[1])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_tsv('/data01/huangyuanhong/hotpot_qa/hotpot_qa_fullwiki_validation.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ed Wood (film) | Ed Wood is a 1994 American biographical period comedy-drama film directed and produced by Tim Burton, and starring Johnny Depp as cult filmmaker Ed Wood.\\\\n The film concerns the period in Wood's life when he made his best-known films as well as his relationship with actor Bela Lugosi, played by Martin Landau.\\\\n Sarah Jessica Parker, Patricia Arquette, Jeffrey Jones, Lisa Marie, and Bill Murray are among the supporting cast.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取tsv文件\n",
    "def read_tsv(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            yield line.strip().split(\"\\t\")\n",
    "\n",
    "\n",
    "file_path = \"./wiki/enwiki-dec2021/collection100.tsv\"\n",
    "output_file = \"./wiki/enwiki-dec2021/collection100_2.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (pid, passage) in enumerate(read_tsv(file_path)):\n",
    "    with open(output_file, \"a\", encoding=\"utf-8\") as file:\n",
    "        file.write(f\"{i}\\t{passage}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
