## data
train_file: data/pretrain/train-2000000.jsonl
max_seq_length: 512
retrieval_context_single_max_len: 180
max_retrieval_context_length: 180
preprocessing_num_workers: 8
overwrite_cache: false
max_train_samples: 200000
output_dir: pretrained_model/qwen/
## model
model_name_or_path: Qwen/Qwen2.5-14B-Instruct
chat_format: qwen
retriever_name_or_path: Salesforce/SFR-Embedding-Mistral
## train
task_type: pretrain
workdir: .
learning_rate: 6.0e-3
lr_scheduler_type: linear
warmup_ratio: 0.03
weight_decay: 0.0
num_train_epochs: 1
alpha_nll: 1.0
clip_grad_norm: -1.0
seed: 980406
update_retriever_layers: 0
per_device_train_batch_size: 1
gradient_accumulation_steps: 8
use_split_pretrain: false
## logging
logging_steps: 1
project_name: prirag_pretraining
exp_name: wikipedia_pretrain
checkpointing_steps: "200000" ## string number or epoch